{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Gradient Descent y Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este experimento utilizaremos un dataset de ventas de casas con el fin de identificar la relación entre la variables precio de casa y la calificación de calidad de la misma.\n",
    "\n",
    "Utilizaremos Tensorflow para la definición del modelo, Tensorboard para analizar el error del modelo entre iteraciones y la técnica de gradiente descendente para disminuir el error lo mejor posible entre cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#habilitamos compatibilidad para TensorFlow v1\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de datos\n",
    "dataset = np.load('data/proyecto_training_data.npy')\n",
    "\n",
    "#escalamos los valores las variables SalePrice en 1000 para que los cálculos del error no sean elevados duratne el entrenamiento\n",
    "dataset[0:, 0]/= 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el dataset, seleccionamos la variable SalesPrice como la variable dependiente y la variable OverallQuall como la variable explicativa.\n",
    "\n",
    "Al realizar una gráfica de relación entre estas variables se puede identificar que existe una relación lineal positiva entre estas variables ya que, al incrementar la calidad de la casa, incrementa su precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataset[:,1].reshape(-1,1)\n",
    "y = dataset[:,0].reshape(-1,1)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Relación SalesPrice vs OverallQual \", FontSize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Modelo\n",
    "\n",
    "Ya que se identificó una relación lineal entre las variables, se definirá regresión lineal donde la hipótesis es el precio de la casa y sus pesos serán la pendiente de la recta y su intercepto.\n",
    "\n",
    "###  <center>$h(x)= mx + b$</center>\n",
    "\n",
    "Para la definición del modelo se utilizará tensorflow y este será calculado por medio de operaciones vectorizadas definidas por grafos, utilizando la técnica de gradiente descendente para optimizar la busqueda de los coeficientes del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y , epochs, lr, print_interval):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.name_scope(\"Pesos_m_b\"):\n",
    "        weights = tf.Variable(name=\"Weights\", initial_value=tf.zeros((2,1),tf.float64))\n",
    "        x = tf.concat([x,tf.ones_like(x)], axis = 1)\n",
    "    with tf.name_scope(\"Evaluar_Hipotesis\"):\n",
    "        y_hat = tf.matmul(x,weights)\n",
    "    with tf.name_scope(\"Calcular_Error\"):\n",
    "        error = (0.5*tf.reduce_mean(tf.math.square(y - y_hat)))\n",
    "    with tf.name_scope(\"Calcular_Gradientes\"):\n",
    "        gradients = tf.gradients(error ,weights)\n",
    "    with tf.name_scope(\"Actualizar_Pesos\"):\n",
    "        update_weights = tf.assign(weights,(tf.add(weights,tf.scalar_mul(-lr,gradients[0]))))\n",
    "\n",
    "    error_summary = tf.summary.scalar(name='Error vs Epochs', tensor=error)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        curr_datetime = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        writer = tf.summary.FileWriter(\"./tensorboard_logs/\"+curr_datetime+\"_lr=\"+str(lr)+\"_epochs=\"+str(epochs),session.graph)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(0,epochs):\n",
    "            if ((epoch+1) % print_interval) == 0:\n",
    "                print(\"epoch:\"+str(epoch+1)+\" error: \"+str(session.run(error)))\n",
    "      \n",
    "            writer.add_summary(session.run(error_summary), epoch)\n",
    "            session.run(update_weights)\n",
    "\n",
    "\n",
    "        writer.close()\n",
    "    session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo del Modelo\n",
    "<img alt=\"Grafo del Modelo\" src=\"images/graph.png\" />\n",
    "\n",
    "Por medio de Tensorboard es posible obtener la definición gráfica de las operaciones realizadas por grafos. Para simplicidad explicativa del modelo se han agrupado algunas operaciones de grafos con name_scopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentando con epochs y learning rate \n",
    "\n",
    "Ya se ha definido la función del modelo, nos falta encontrar cual es el learning rate y la cantidad de iteraciones que nos brindarán el error más bajo. Para esto realizaremos un set de experimentos variando estos 2 parámetros y se estará monitoreando el comportamiento del error por medio de Tensorboard.\n",
    "\n",
    "Comenzaremos con un lr de 0.8 y 100 epochs y a partir de estos resultados iremos verificando si es necesario realizar cambio en alguno de los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 1.3035551349504527e+31\n",
      "epoch:20 error: 9.057111885259299e+60\n",
      "epoch:30 error: 6.292888847023965e+90\n",
      "epoch:40 error: 4.37230438827298e+120\n",
      "epoch:50 error: 3.0378807139986114e+150\n",
      "epoch:60 error: 2.1107220387577006e+180\n",
      "epoch:70 error: 1.4665314225038683e+210\n",
      "epoch:80 error: 1.0189472482397751e+240\n",
      "epoch:90 error: 7.079653928742725e+269\n",
      "epoch:100 error: 4.9189494193489174e+299\n"
     ]
    }
   ],
   "source": [
    "#lr 0.8, epochs 100\n",
    "linear_regression(x,y,100,0.8,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 1\" src=\"images/1.png\" />\n",
    "\n",
    "Como se puede observar en el primer resultado del experimento, el error incrementa conforme se avanza en las iteraciones por lo que el learning rate escogido es muy grande. \n",
    "\n",
    "Para el siguiente experimento se disminuirá el lr esperando que el error disminuya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 7288476744253.572\n",
      "epoch:20 error: 2.654298312445766e+22\n",
      "epoch:30 error: 9.666353862442658e+31\n",
      "epoch:40 error: 3.520267354872502e+41\n",
      "epoch:50 error: 1.2820017171034441e+51\n",
      "epoch:60 error: 4.6687601735173214e+60\n",
      "epoch:70 error: 1.7002568145595184e+70\n",
      "epoch:80 error: 6.191950599334789e+79\n",
      "epoch:90 error: 2.254968302217038e+89\n",
      "epoch:100 error: 8.21208432210344e+98\n"
     ]
    }
   ],
   "source": [
    "#lr 0.1, epochs 100\n",
    "linear_regression(x,y,100,0.1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 2\" src=\"images/2.png\" />\n",
    "\n",
    "Se puede observar el el error comienza a incrementar a partir de las 30 iteraciones, sin embargo, si vemos el último valor obtenido, el error es menor que el último error obtenido.\n",
    "\n",
    "Para el siguiente experimento se disminuirá nuevamente el lr esperando que el error disminuya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 20602.521536667417\n",
      "epoch:20 error: 21883.91539002882\n",
      "epoch:30 error: 23252.90696282639\n",
      "epoch:40 error: 24715.338985641516\n",
      "epoch:50 error: 26277.450587668576\n",
      "epoch:60 error: 27945.903875057462\n",
      "epoch:70 error: 29727.81230592088\n",
      "epoch:80 error: 31630.77098277524\n",
      "epoch:90 error: 33662.88899133415\n",
      "epoch:100 error: 35832.82392326839\n"
     ]
    }
   ],
   "source": [
    "#lr 0.05, epochs 100\n",
    "linear_regression(x,y,100,0.05,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 3\" src=\"images/3.png\" />\n",
    "\n",
    "Nuevamente el error empieza a incrementar a partir de cierto punto por lo que el learning rate todavía es muy grande, sin embargo, se puede observar que el crecimiento es menor por lo que haremos una pequeña disminución del error en el siguiente experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 10630.65658153117\n",
      "epoch:20 error: 5759.733502762275\n",
      "epoch:30 error: 3453.3536089654\n",
      "epoch:40 error: 2358.760115209254\n",
      "epoch:50 error: 1836.8701142588802\n",
      "epoch:60 error: 1585.756370211648\n",
      "epoch:70 error: 1462.771849048464\n",
      "epoch:80 error: 1400.5174294614976\n",
      "epoch:90 error: 1367.1431882269403\n",
      "epoch:100 error: 1347.5938380611099\n"
     ]
    }
   ],
   "source": [
    "#lr 0.049, epochs 100\n",
    "linear_regression(x,y,100,0.049,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 4\" src=\"images/4.png\" />\n",
    "\n",
    "Finalmente se ha encontrado un learning rate que no incrementa el error al incrementar las iteraciones, observando la curva de error obtenida, se puede apreciar la efectividad del gradiente descendente ya que se comienza con un error bastante grande pero en las primeras 30 iteraciones disminuye de gran manera y a partir de allí el error disminuye poco a poco.\n",
    "\n",
    "Para el siguiente experimento se utilizará un learning rate más bajo para validar si se tiene un mejor error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 1428.621318236252\n",
      "epoch:20 error: 1424.479865308545\n",
      "epoch:30 error: 1422.1621322921783\n",
      "epoch:40 error: 1419.866477287337\n",
      "epoch:50 error: 1417.5926267617533\n",
      "epoch:60 error: 1415.3403736109176\n",
      "epoch:70 error: 1413.1095126997097\n",
      "epoch:80 error: 1410.8998408414168\n",
      "epoch:90 error: 1408.7111567792233\n",
      "epoch:100 error: 1406.5432611678807\n"
     ]
    }
   ],
   "source": [
    "#lr 0.01, epochs 100\n",
    "linear_regression(x,y,100,0.01,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 5\" src=\"images/5.png\" />\n",
    "\n",
    "Esta vez hemos obtenido un comportamiento similar al experimento anterior con un error levemente mayor, por lo cual podemos decir que el learning rate es muy bajo y con la misma cantidad de iteraciones, este se queda en un error más bajo.\n",
    "\n",
    "Para confirmar los resultados obtenidos en el experimento anterior se realizará nuevamente el experimento con un lr más bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 10094.468145327142\n",
      "epoch:20 error: 5253.563423040175\n",
      "epoch:30 error: 3116.6490403030793\n",
      "epoch:40 error: 2173.280032532253\n",
      "epoch:50 error: 1756.743806349415\n",
      "epoch:60 error: 1572.7524580619684\n",
      "epoch:70 error: 1491.4068809715511\n",
      "epoch:80 error: 1455.3694212739204\n",
      "epoch:90 error: 1439.3311554821476\n",
      "epoch:100 error: 1432.1206880229308\n"
     ]
    }
   ],
   "source": [
    "#lr 0.001, epochs 100\n",
    "linear_regression(x,y,100,0.001,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 6\" src=\"images/6.png\" />\n",
    "\n",
    "Con esto confirmamos las hipotesis realizada, el learning rate es muy bajo para 100 iteraciones por lo que al disminuirlo, se obtiene un error mayor.\n",
    "\n",
    "En este experimento se disminuirá nuevamente el learning rate para validar que tan lento decrece el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 error: 18258.451722429138\n",
      "epoch:20 error: 16959.983372981675\n",
      "epoch:30 error: 15761.693620638041\n",
      "epoch:40 error: 14655.853409788304\n",
      "epoch:50 error: 13635.330002835506\n",
      "epoch:60 error: 12693.54097261203\n",
      "epoch:70 error: 11824.411744408157\n",
      "epoch:80 error: 11022.336413750658\n",
      "epoch:90 error: 10282.141587198059\n",
      "epoch:100 error: 9599.053012918552\n"
     ]
    }
   ],
   "source": [
    "#lr 0.0001, epochs 100\n",
    "linear_regression(x,y,100,0.0001,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 7\" src=\"images/7.png\" />\n",
    "\n",
    "Con este resultado podemos concluír que el lr 0.0001 es muy bajo ya que con 100 iteraciones este no llega a converger, obteniendo un error bastante alto.\n",
    "\n",
    "Ya que hemos experimentado con diferentes learning rate, se procederá a utilizar un lr de 0.001 que dio buenos resultados y se realizarán más iteraciones, esperando que el error sea aún menor que con 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:100 error: 1432.1206880229308\n",
      "epoch:200 error: 1424.2728454219214\n",
      "epoch:300 error: 1421.956104939894\n",
      "epoch:400 error: 1419.6628965028528\n",
      "epoch:500 error: 1417.3914650808324\n",
      "epoch:600 error: 1415.141603446656\n",
      "epoch:700 error: 1412.9131067708877\n",
      "epoch:800 error: 1410.705772169294\n",
      "epoch:900 error: 1408.519398684262\n",
      "epoch:1000 error: 1406.353787266486\n"
     ]
    }
   ],
   "source": [
    "#lr 0.001, epochs 1000\n",
    "linear_regression(x,y,1000,0.001,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 8\" src=\"images/8.png\" />\n",
    "\n",
    "Tal como se supuso, al tener más iteraciones se ha obenido un error menor, a partir de las 70 iteraciones el modelo converge y el error disminuye lentamente.\n",
    "\n",
    "Probaremos con 10,000 iteraciones esperando a que el error disminuya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1000 error: 1406.353787266486\n",
      "epoch:2000 error: 1385.797124620955\n",
      "epoch:3000 error: 1367.111207634297\n",
      "epoch:4000 error: 1350.1257903195788\n",
      "epoch:5000 error: 1334.686119814719\n",
      "epoch:6000 error: 1320.6515264407867\n",
      "epoch:7000 error: 1307.8941420711112\n",
      "epoch:8000 error: 1296.2977351343836\n",
      "epoch:9000 error: 1285.7566516375302\n",
      "epoch:10000 error: 1276.1748525601176\n"
     ]
    }
   ],
   "source": [
    "#lr 0.001, epochs 10000\n",
    "linear_regression(x,y,10000,0.001,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 9\" src=\"images/9.png\" />\n",
    "\n",
    "Se confirma que se ha obtenido un mejor error con más iteraciones por lo que se realizará un último experimento con 100,000 iteraciones esperando obtener como resultado un menor error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10000 error: 1276.1748525601176\n",
      "epoch:20000 error: 1217.3279888453515\n",
      "epoch:30000 error: 1194.6637370956987\n",
      "epoch:40000 error: 1185.9348384773891\n",
      "epoch:50000 error: 1182.572994815823\n",
      "epoch:60000 error: 1181.278216024246\n",
      "epoch:70000 error: 1180.7795455660428\n",
      "epoch:80000 error: 1180.5874878744123\n",
      "epoch:90000 error: 1180.513518870818\n",
      "epoch:100000 error: 1180.4850304856554\n"
     ]
    }
   ],
   "source": [
    "#lr 0.001, epochs 100000\n",
    "linear_regression(x,y,100000,0.001,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Experimento 10\" src=\"images/10.png\" />\n",
    "\n",
    "Tal como se esperaba, se ha obtenido un error menor al incrementar nuevamente las iteraciones.\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "- El uso de gradiente descendente nos ayuda optimizar la búsqueda de los coeficientes que nos permitan realizar un modelo de predicción en vez de hacerlo por medio de fuerza bruta, lo cual consumiría más tiempo y recursos.\n",
    "\n",
    "\n",
    "- Debido a que encontrar el learning rate o iteraciones necesarias para obtener un modelo con un error o costo aceptable, requiere realizar pruebas manualmente, es importante tener herramientas que nos den ese feedback para saber si estamos utilizando los valores adecuados de las funciones, en este caso Tensorboard es una excelente herramienta en nuestro arsenal para este tipo de experimentos ya que nos permite mostrar en tiempo real los resultados obtenidos durante la prueba de nuestro modelo.\n",
    "\n",
    "\n",
    "- Otra de las ventajas que nos brinda Tensorboard es que puede almacenar el registro de diferentes corridas del modelo, y nos permite visualizar en una misma gráfica más de un registro a la vez, permitiendonos hacer comparaciones, tal como en la gráfica mostrada a continuación, permitiendonos evaluar cuales parametros son más convenientes para el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Resumen\" src=\"images/summary.png\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
